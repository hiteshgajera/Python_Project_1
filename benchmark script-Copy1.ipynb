{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.cross_validation import train_test_split,KFold\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datafile_train=r'C:\\Users\\id832393\\Documents\\Personal\\Data science\\Python\\Projects\\Project1\\Data\\Consumer_Complaints_train.csv'\n",
    "datafile_test=r'C:\\Users\\id832393\\Documents\\Personal\\Data science\\Python\\Projects\\Project1\\Data\\Consumer_Complaints_test_share.csv'\n",
    "cd_train=pd.read_csv(datafile_train)\n",
    "cd_test=pd.read_csv(datafile_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(cd_train.shape)\n",
    "print(cd_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cd_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cd_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "cd_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#add response column in test data frame\n",
    "cd_test['Consumer disputed?']=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#add flag column for test or train data indication\n",
    "cd_train['data']='train'\n",
    "cd_test['data']='test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#aling column sequence in both dataframe\n",
    "cd_test=cd_test[cd_train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#combine both dataset\n",
    "cd_all = pd.concat([cd_train, cd_test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cd_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#gives type and unique values in each column.\n",
    "list(zip(cd_all.columns, cd_all.dtypes, cd_all.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert the columns into date time\n",
    "for col in ['Date received','Date sent to company']:\n",
    "    cd_train[col]=pd.to_datetime(cd_train[col],infer_datetime_format=True)\n",
    "    cd_test[col]=pd.to_datetime(cd_test[col],infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add new column day difference, derived from available columns\n",
    "cd_train['day_diff']=pd.to_numeric(cd_train['Date sent to company']-cd_train['Date received'])\n",
    "cd_test['day_diff']=pd.to_numeric(cd_test['Date sent to company']-cd_test['Date received'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in ['Date received','Date sent to company']:\n",
    "    cd_train.drop([col],1,inplace=True)\n",
    "    cd_test.drop([col],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(478421, 17)\n",
      "(119606, 16)\n"
     ]
    }
   ],
   "source": [
    "print(cd_train.shape)\n",
    "print(cd_test.shape)\n",
    "#print(cd_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product                         object\n",
       "Sub-product                     object\n",
       "Issue                           object\n",
       "Sub-issue                       object\n",
       "Consumer complaint narrative    object\n",
       "Company public response         object\n",
       "Company                         object\n",
       "State                           object\n",
       "ZIP code                        object\n",
       "Tags                            object\n",
       "Consumer consent provided?      object\n",
       "Submitted via                   object\n",
       "Company response to consumer    object\n",
       "Timely response?                object\n",
       "Consumer disputed?              object\n",
       "Complaint ID                     int64\n",
       "day_diff                         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product                              0\n",
       "Sub-product                     138473\n",
       "Issue                                0\n",
       "Sub-issue                       292625\n",
       "Consumer complaint narrative    403327\n",
       "Company public response         388029\n",
       "Company                              0\n",
       "State                             3839\n",
       "ZIP code                          3848\n",
       "Tags                            411215\n",
       "Consumer consent provided?      342934\n",
       "Submitted via                        0\n",
       "Company response to consumer         0\n",
       "Timely response?                     0\n",
       "Consumer disputed?                   0\n",
       "Complaint ID                         0\n",
       "day_diff                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product : 12\n",
      "Sub-product : 47\n",
      "Issue : 95\n",
      "Sub-issue : 68\n",
      "Consumer complaint narrative : 74019\n",
      "Company public response : 10\n",
      "Company : 3276\n",
      "State : 62\n",
      "ZIP code : 25962\n",
      "Tags : 3\n",
      "Consumer consent provided? : 4\n",
      "Submitted via : 6\n",
      "Company response to consumer : 7\n",
      "Timely response? : 2\n",
      "Consumer disputed? : 2\n"
     ]
    }
   ],
   "source": [
    "for col in cd_train.select_dtypes(['object']).columns:\n",
    "    print(col,':',cd_train[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Consent provided', 'Other', 'Consent not provided',\n",
       "       'Consent withdrawn'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd_train['Consumer consent provided?'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Sub-product                     138473\n",
    "Sub-issue                       292625\n",
    "Consumer complaint narrative    403327\n",
    "Company public response         388029\n",
    "State                             3839\n",
    "ZIP code                          3848\n",
    "Tags                            411215\n",
    "Consumer consent provided?      342934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478421"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.isnull(cd_train['Tags']))\n",
    "#len(cd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in ['Sub-product','Sub-issue','Consumer complaint narrative',\n",
    "            'Company public response','Tags','Consumer consent provided?']:\n",
    "    varname=col.replace('-','_').replace('?','').replace(\" \",'_')+'_isNan'\n",
    "    cd_train[varname]=np.where(pd.isnull(cd_train[col]),1,0)\n",
    "    cd_train.drop([col],1,inplace=True)\n",
    "    cd_test[varname]=np.where(pd.isnull(cd_test[col]),1,0)\n",
    "    cd_test.drop([col],1,inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product : 12\n",
      "Issue : 95\n",
      "Company : 3276\n",
      "State : 62\n",
      "ZIP code : 25962\n",
      "Submitted via : 6\n",
      "Company response to consumer : 7\n",
      "Timely response? : 2\n",
      "Consumer disputed? : 2\n"
     ]
    }
   ],
   "source": [
    "for col in cd_train.select_dtypes(['object']).columns:\n",
    "    print(col,':',cd_train[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in ['ZIP code','Company']:\n",
    "    cd_train.drop([col],1,inplace=True)\n",
    "    cd_test.drop([col],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd_train['Consumer disputed?']=np.where(cd_train['Consumer disputed?']==\"Yes\",1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k=cd_train['Issue'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan modification,collection,foreclosure    80302\n",
       "Incorrect information on credit report      58527\n",
       "Loan servicing, payments, escrow account    51403\n",
       "Cont'd attempts collect debt not owed       36367\n",
       "Account opening, closing, or management     23568\n",
       "Disclosure verification of debt             16235\n",
       "Communication tactics                       15312\n",
       "Deposits and withdrawals                    14721\n",
       "Application, originator, mortgage broker    11201\n",
       "Billing disputes                             9600\n",
       "Credit reporting company's investigation     9492\n",
       "Other                                        9442\n",
       "Managing the loan or lease                   8905\n",
       "Problems caused by my funds being low        7758\n",
       "False statements or representation           7074\n",
       "Unable to get credit report/credit score     7060\n",
       "Dealing with my lender or servicer           6460\n",
       "Improper contact or sharing of info          6182\n",
       "Problems when you are unable to pay          5921\n",
       "Settlement process and costs                 5834\n",
       "Taking/threatening an illegal action         5374\n",
       "Identity theft / Fraud / Embezzlement        5141\n",
       "Making/receiving payments, sending money     4618\n",
       "Closing/Cancelling account                   4088\n",
       "APR or interest rate                         3870\n",
       "Credit decision / Underwriting               3755\n",
       "Using a debit or ATM card                    3738\n",
       "Can't repay my loan                          3668\n",
       "Improper use of my credit report             3283\n",
       "Repaying your loan                           2988\n",
       "                                            ...  \n",
       "Bankruptcy                                    321\n",
       "Can't stop charges to bank account            293\n",
       "Payment to acct not credited                  266\n",
       "Applied for loan/did not receive money        232\n",
       "Arbitration                                   225\n",
       "Sale of account                               223\n",
       "Shopping for a line of credit                 202\n",
       "Wrong amount charged or received              180\n",
       "Charged bank acct wrong day or amt            164\n",
       "Cash advance                                  163\n",
       "Customer service/Customer relations           151\n",
       "Overlimit fee                                 145\n",
       "Adding money                                  143\n",
       "Fees                                          142\n",
       "Balance transfer fee                          141\n",
       "Incorrect/missing disclosures or info         129\n",
       "Cash advance fee                              128\n",
       "Convenience checks                            100\n",
       "Excessive fees                                 52\n",
       "Unexpected/Other fees                          52\n",
       "Advertising, marketing or disclosures          50\n",
       "Lender repossessed or sold the vehicle         39\n",
       "Overdraft, savings or rewards features         29\n",
       "Disclosures                                    26\n",
       "Lost or stolen money order                     25\n",
       "Lost or stolen check                           20\n",
       "Incorrect exchange rate                        13\n",
       "Lender damaged or destroyed vehicle             5\n",
       "Lender sold the property                        2\n",
       "Lender damaged or destroyed property            1\n",
       "Name: Issue, Length: 95, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for val in k.axes[0][0:10]:\n",
    "    varname='Issue_'+val.replace(',','_').replace(' ','_')\n",
    "    cd_train[varname]=np.where(cd_train['Issue']==val,1,0)\n",
    "    cd_test[varname]=np.where(cd_test['Issue']==val,1,0)\n",
    "del cd_train['Issue']\n",
    "del cd_test['Issue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product : 12\n",
      "State : 62\n",
      "Submitted via : 6\n",
      "Company response to consumer : 7\n",
      "Timely response? : 2\n"
     ]
    }
   ],
   "source": [
    "for col in cd_train.select_dtypes(['object']).columns:\n",
    "    print(col,':',cd_train[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k=cd_train['State'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA    70001\n",
       "FL    46089\n",
       "TX    35895\n",
       "NY    32750\n",
       "GA    21258\n",
       "NJ    19369\n",
       "PA    17109\n",
       "IL    16947\n",
       "VA    15613\n",
       "MD    15281\n",
       "OH    14831\n",
       "NC    13347\n",
       "MI    12377\n",
       "AZ    10691\n",
       "WA    10024\n",
       "MA     9584\n",
       "CO     8231\n",
       "TN     7383\n",
       "MO     6221\n",
       "SC     6000\n",
       "NV     5838\n",
       "OR     5698\n",
       "MN     5587\n",
       "CT     5582\n",
       "IN     5303\n",
       "WI     5259\n",
       "AL     4950\n",
       "LA     4776\n",
       "KY     3419\n",
       "OK     3172\n",
       "      ...  \n",
       "DE     2510\n",
       "NH     2404\n",
       "NM     2389\n",
       "KS     2370\n",
       "MS     2195\n",
       "AR     2075\n",
       "IA     1947\n",
       "ID     1684\n",
       "ME     1663\n",
       "HI     1658\n",
       "RI     1632\n",
       "NE     1497\n",
       "WV     1229\n",
       "PR     1140\n",
       "VT      804\n",
       "MT      738\n",
       "SD      631\n",
       "AK      552\n",
       "WY      459\n",
       "ND      417\n",
       "AE      195\n",
       "AP      132\n",
       "VI      121\n",
       "GU       60\n",
       "FM       30\n",
       "MH       25\n",
       "MP       15\n",
       "AS       14\n",
       "PW        9\n",
       "AA        8\n",
       "Name: State, Length: 62, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for val in k.axes[0][0:15]:\n",
    "    varname='State_'+val.replace(',','_').replace(' ','_')\n",
    "    cd_train[varname]=np.where(cd_train['State']==val,1,0)\n",
    "    cd_test[varname]=np.where(cd_test['State']==val,1,0)\n",
    "del cd_train['State']\n",
    "del cd_test['State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in ['Product','Submitted via','Company response to consumer','Timely response?']:\n",
    "    \n",
    "    temp=pd.get_dummies(cd_train[col],prefix=col,drop_first=True)\n",
    "    cd_train=pd.concat([temp,cd_train],1)\n",
    "    cd_train.drop([col],1,inplace=True)\n",
    "    \n",
    "    temp=pd.get_dummies(cd_test[col],prefix=col,drop_first=True)\n",
    "    cd_test=pd.concat([temp,cd_test],1)\n",
    "    cd_test.drop([col],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=cd_train.drop(['Consumer disputed?','Complaint ID'],1)\n",
    "y=cd_train['Consumer disputed?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cd_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#remove data column from train and test dataframe\n",
    "del cd_train['data']\n",
    "del cd_test['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use random search model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "\n",
    "param_dist = {\"n_estimators\":[100,200,300,500,700,1000],\n",
    "              \"max_features\": [5,10,20,25,30,35],\n",
    "              \"bootstrap\": [True, False],\n",
    "              'class_weight':[None,'balanced'], \n",
    "                'criterion':['entropy','gini'],\n",
    "                'max_depth':[None,5,10,15,20,30,50,70],\n",
    "                'min_samples_leaf':[1,2,5,10,15,20], \n",
    "                'min_samples_split':[2,5,10,15,20]\n",
    "                  }\n",
    "\n",
    "n_iter_search = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=n_iter_search,scoring='roc_auc',cv=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 43.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=1, n_jobs=1,\n",
       "          param_distributions={'n_estimators': [100, 200, 300, 500, 700, 1000], 'max_features': [5, 10, 20, 25, 30, 35], 'bootstrap': [True, False], 'class_weight': [None, 'balanced'], 'criterion': ['entropy', 'gini'], 'max_depth': [None, 5, 10, 15, 20, 30, 50, 70], 'min_samples_leaf': [1, 2, 5, 10, 15, 20], 'min_samples_split': [2, 5, 10, 15, 20]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None,\n",
       "            criterion='entropy', max_depth=15, max_features=35,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=300, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Report function\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.5f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.618 (std: 0.00093)\n",
      "Parameters: {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 35, 'max_depth': 15, 'criterion': 'entropy', 'class_weight': None, 'bootstrap': False}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(random_search.cv_results_,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_rf = RandomForestClassifier(bootstrap=False, class_weight=None,\n",
    "            criterion='entropy', max_depth=15, max_features=35,\n",
    "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=1,\n",
    "            min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=300, n_jobs=1, oob_score=False, random_state=None,\n",
    "            verbose=1, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed: 18.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None,\n",
       "            criterion='entropy', max_depth=15, max_features=35,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=300, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rf.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478421, 55)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test=cd_test.drop(['Complaint ID'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119606, 55)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   11.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    9.8s finished\n"
     ]
    }
   ],
   "source": [
    "prediction=np.where(new_rf.predict(cd_test.drop(['Complaint ID'],1))==1,\"Yes\",\"No\")\n",
    "submission=pd.DataFrame(list(zip(cd_test['Complaint ID'],list(prediction))),\n",
    "                       columns=['Complaint ID','Consumer disputed?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Complaint ID</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>675956</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1858795</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32637</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1731374</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Complaint ID Consumer disputed?\n",
       "0        675956                 No\n",
       "1       1858795                 No\n",
       "2         32637                 No\n",
       "3       1731374                 No"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params={'class_weight':['balanced',None],\n",
    " 'penalty':['l1','l2'],\n",
    " 'C':np.linspace(0.01,50,10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search=GridSearchCV(clf,param_grid=params,cv=5,scoring=\"roc_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logr=grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                results['mean_test_score'][candidate],\n",
    "                results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report(grid_search.cv_results_,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = logr.predict_proba(cd_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction=np.where(clf.predict(cd_test.drop(['Complaint ID'],1))==1,\"Yes\",\"No\")\n",
    "submission=pd.DataFrame(list(zip(cd_test['Complaint ID'],list(prediction))),\n",
    "                       columns=['Complaint ID','Consumer disputed?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission will get you auc score of approx 0.50, slightly less than whats required for passing the course. You'll have to make changes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
